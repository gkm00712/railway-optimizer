import streamlit as st
import pandas as pd
from datetime import timedelta, datetime
import pytz
import math
import numpy as np
import re

# ==========================================
# 1. PAGE CONFIGURATION & INPUTS
# ==========================================
st.set_page_config(page_title="Railway Logic Optimizer (IST)", layout="wide")
st.title("ğŸš‚ BOXN & BOBR Rake Logistics Dashboard (IST)")

IST = pytz.timezone('Asia/Kolkata')

# --- SIDEBAR INPUTS ---
st.sidebar.header("âš™ï¸ Settings")
gs_url = st.sidebar.text_input("Google Sheet CSV Link", value="https://docs.google.com/spreadsheets/d/e/2PACX-1vTlqPtwJyVkJYLs3V2t1kMw0It1zURfH3fU7vtLKX0BaQ_p71b2xvkH4NRazgD9Bg/pub?output=csv")

show_history = st.sidebar.checkbox("Show All Historical Data", value=False, help="Check this to see old completed rakes")

st.sidebar.markdown("---")
sim_params = {}
sim_params['rt1'] = st.sidebar.number_input("Tippler 1 Rate", value=6.0, step=0.5)
sim_params['rt2'] = st.sidebar.number_input("Tippler 2 Rate", value=6.0, step=0.5)
sim_params['rt3'] = st.sidebar.number_input("Tippler 3 Rate", value=9.0, step=0.5)
sim_params['rt4'] = st.sidebar.number_input("Tippler 4 Rate", value=9.0, step=0.5)
st.sidebar.markdown("---")
sim_params['sa'] = st.sidebar.number_input("Pair A Shunt (Mins)", value=25.0, step=5.0)
sim_params['sb'] = st.sidebar.number_input("Pair B Shunt (Mins)", value=50.0, step=5.0)
sim_params['extra_shunt'] = st.sidebar.number_input("Cross-Pair Penalty (Mins)", value=45.0, step=5.0)
st.sidebar.markdown("---")
sim_params['fa'] = st.sidebar.number_input("Pair A Formation (Mins)", value=20.0, step=5.0)
sim_params['fb'] = st.sidebar.number_input("Pair B Formation (Mins)", value=50.0, step=5.0)
sim_params['ft'] = st.sidebar.number_input("Free Time (Hours)", value=7.0, step=0.5)
sim_params['wb'] = st.sidebar.number_input("Wagons 1st Batch", value=30, step=1)
sim_params['wd'] = st.sidebar.number_input("Delay 2nd Tippler (Mins)", value=0.0, step=5.0)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ› ï¸ Tippler Downtime")
if 'downtimes' not in st.session_state: st.session_state.downtimes = []
with st.sidebar.form("downtime_form"):
Â  Â  dt_tippler = st.selectbox("Select Tippler", ["T1", "T2", "T3", "T4"])
Â  Â  now_ist = datetime.now(IST)
Â  Â  dt_start_date = st.date_input("Start Date", value=now_ist.date())
Â  Â  dt_start_time = st.time_input("Start Time", value=now_ist.time())
Â  Â  dt_duration = st.number_input("Duration (Minutes)", min_value=15, step=15, value=60)
Â  Â  if st.form_submit_button("Add Downtime"):
Â  Â  Â  Â  start_dt = IST.localize(datetime.combine(dt_start_date, dt_start_time))
Â  Â  Â  Â  st.session_state.downtimes.append({"Tippler": dt_tippler, "Start": start_dt, "End": start_dt + timedelta(minutes=dt_duration)})
Â  Â  Â  Â  st.rerun()

if st.session_state.downtimes:
Â  Â  dt_df = pd.DataFrame(st.session_state.downtimes)
Â  Â  st.sidebar.dataframe(dt_df.assign(Start=lambda x: x['Start'].dt.strftime('%d-%H:%M'), End=lambda x: x['End'].dt.strftime('%d-%H:%M'))[['Tippler', 'Start', 'End']], use_container_width=True)
Â  Â  if st.sidebar.button("Clear Downtimes"):
Â  Â  Â  Â  st.session_state.downtimes = []
Â  Â  Â  Â  st.rerun()
sim_params['downtimes'] = st.session_state.downtimes

curr_params_hash = str(sim_params)
params_changed = False
if 'last_params_hash' not in st.session_state:
Â  Â  st.session_state.last_params_hash = curr_params_hash
elif st.session_state.last_params_hash != curr_params_hash:
Â  Â  params_changed = True
Â  Â  st.session_state.last_params_hash = curr_params_hash

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================

def to_ist(dt):
Â  Â  if pd.isnull(dt): return pd.NaT
Â  Â  if dt.tzinfo is None: return IST.localize(dt)
Â  Â  return dt.astimezone(IST)

def parse_wagons(val):
Â  Â  try:
Â  Â  Â  Â  val_str = str(val).strip()
Â  Â  Â  Â  if '+' in val_str:
Â  Â  Â  Â  Â  Â  parts = val_str.split('+')
Â  Â  Â  Â  Â  Â  return sum(int(p) for p in parts if p.strip().isdigit())
Â  Â  Â  Â  return int(float(val_str))
Â  Â  except: return 0

def format_dt(dt):
Â  Â  if pd.isnull(dt): return ""
Â  Â  if dt.tzinfo is None: dt = IST.localize(dt)
Â  Â  return dt.strftime('%d-%H:%M')

# FIXED: Logic to use Reference Date (Arrival) instead of Current Date
def parse_dt_from_str_smart(dt_str, ref_dt_obj):
Â  Â  try:
Â  Â  Â  Â  if not dt_str: return pd.NaT
Â  Â  Â  Â  parts = dt_str.split('-')
Â  Â  Â  Â  day = int(parts[0])
Â  Â  Â  Â  hm = parts[1].split(':')
Â  Â  Â  Â  h, m = int(hm[0]), int(hm[1])
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Use Month/Year from Reference Object (Arrival Date)
Â  Â  Â  Â  if pd.isnull(ref_dt_obj):
Â  Â  Â  Â  Â  Â  year_ref = datetime.now().year
Â  Â  Â  Â  Â  Â  month_ref = datetime.now().month
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  year_ref = ref_dt_obj.year
Â  Â  Â  Â  Â  Â  month_ref = ref_dt_obj.month
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  dt = datetime(year_ref, month_ref, day, h, m)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Handle month rollover (e.g. Arrival 31st Jan, Unload 1st Feb)
Â  Â  Â  Â  # If created date is much earlier than arrival, it likely belongs to next month
Â  Â  Â  Â  if pd.notnull(ref_dt_obj):
Â  Â  Â  Â  Â  Â  Â naive_ref = ref_dt_obj.replace(tzinfo=None)
Â  Â  Â  Â  Â  Â  Â if (dt - naive_ref).days < -20: # If it looks like a month behind
Â  Â  Â  Â  Â  Â  Â  Â  Â # Add roughly a month? Simplest is to rely on the day number
Â  Â  Â  Â  Â  Â  Â  Â  Â if month_ref == 12:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â dt = dt.replace(year=year_ref+1, month=1)
Â  Â  Â  Â  Â  Â  Â  Â  Â else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â dt = dt.replace(month=month_ref+1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â 
Â  Â  Â  Â  return IST.localize(dt)
Â  Â  except: return pd.NaT

def format_duration_hhmm(delta):
Â  Â  if pd.isnull(delta): return ""
Â  Â  total_seconds = int(delta.total_seconds())
Â  Â  sign = "-" if total_seconds < 0 else ""
Â  Â  total_seconds = abs(total_seconds)
Â  Â  hours = total_seconds // 3600
Â  Â  minutes = (total_seconds % 3600) // 60
Â  Â  return f"{sign}{hours:02d}:{minutes:02d}"

def calculate_rounded_demurrage(duration_delta, free_time_hours):
Â  Â  if pd.isnull(duration_delta): return "00:00", 0
Â  Â  total_minutes = duration_delta.total_seconds() / 60
Â  Â  free_minutes = free_time_hours * 60
Â  Â  demurrage_minutes = total_minutes - free_minutes
Â  Â  if demurrage_minutes <= 0: return "00:00", 0
Â  Â  rounded_hours = math.ceil(demurrage_minutes / 60)
Â  Â  return f"{int(rounded_hours):02d}:00", rounded_hours

def check_downtime_impact(tippler_id, proposed_start, downtime_list):
Â  Â  if proposed_start.tzinfo is None: proposed_start = IST.localize(proposed_start)
Â  Â  relevant_dts = [d for d in downtime_list if d['Tippler'] == tippler_id]
Â  Â  relevant_dts.sort(key=lambda x: x['Start'])
Â  Â  current_start = proposed_start
Â  Â  changed = True
Â  Â  while changed:
Â  Â  Â  Â  changed = False
Â  Â  Â  Â  for dt in relevant_dts:
Â  Â  Â  Â  Â  Â  if dt['Start'] <= current_start < dt['End']:
Â  Â  Â  Â  Â  Â  Â  Â  current_start = dt['End']
Â  Â  Â  Â  Â  Â  Â  Â  changed = True
Â  Â  return current_start

def find_column(df, candidates):
Â  Â  cols_upper = [str(c).upper().strip() for c in df.columns]
Â  Â  for cand in candidates:
Â  Â  Â  Â  cand_upper = cand.upper().strip()
Â  Â  Â  Â  if cand_upper in cols_upper: return df.columns[cols_upper.index(cand_upper)]
Â  Â  Â  Â  for c in cols_upper:
Â  Â  Â  Â  Â  Â  if cand_upper == c: return df.columns[cols_upper.index(c)]
Â  Â  return None

def parse_last_sequence(rake_name):
Â  Â  try:
Â  Â  Â  Â  s = str(rake_name).strip()
Â  Â  Â  Â  match_complex = re.search(r'(\d+)\D+(\d+)', s)
Â  Â  Â  Â  if match_complex:
Â  Â  Â  Â  Â  Â  return int(match_complex.group(1)), int(match_complex.group(2))
Â  Â  Â  Â  match_single = re.search(r'^(\d+)', s)
Â  Â  Â  Â  if match_single:
Â  Â  Â  Â  Â  Â  val = int(match_single.group(1))
Â  Â  Â  Â  Â  Â  if val > 1000: return 0, val
Â  Â  Â  Â  Â  Â  return val, 0
Â  Â  except: pass
Â  Â  return 0, 0

def parse_tippler_cell(cell_value, ref_date):
Â  Â  if pd.isnull(cell_value): return pd.NaT, pd.NaT
Â  Â  s = str(cell_value).strip()
Â  Â  times_found = re.findall(r'(\d{1,2}:\d{2})', s)
Â  Â  if len(times_found) >= 2:
Â  Â  Â  Â  start_str, end_str = times_found[0], times_found[1]
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  if ref_date.tzinfo is None: ref_date = IST.localize(ref_date)
Â  Â  Â  Â  Â  Â  s_h, s_m = map(int, start_str.split(':'))
Â  Â  Â  Â  Â  Â  e_h, e_m = map(int, end_str.split(':'))
Â  Â  Â  Â  Â  Â  start_dt = ref_date.replace(hour=s_h, minute=s_m, second=0, microsecond=0)
Â  Â  Â  Â  Â  Â  end_dt = ref_date.replace(hour=e_h, minute=e_m, second=0, microsecond=0)
Â  Â  Â  Â  Â  Â  if end_dt < start_dt: end_dt += timedelta(days=1)
Â  Â  Â  Â  Â  Â  if (start_dt - ref_date).total_seconds() < -43200:Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â start_dt += timedelta(days=1); end_dt += timedelta(days=1)
Â  Â  Â  Â  Â  Â  return start_dt, end_dt
Â  Â  Â  Â  except: pass
Â  Â  return pd.NaT, pd.NaT

def parse_wagon_count_from_cell(cell_value):
Â  Â  if pd.isnull(cell_value): return None
Â  Â  s = str(cell_value).strip()
Â  Â  clean_s = re.sub(r'\d{1,2}:\d{2}', '', s)
Â  Â  matches = re.findall(r'\b(\d{1,3})\b', clean_s)
Â  Â  if matches:
Â  Â  Â  Â  return int(matches[0])Â 
Â  Â  return None

def parse_col_d_wagon_type(cell_val):
Â  Â  wagons = 58Â 
Â  Â  load_type = 'BOXN'Â 
Â  Â  if pd.isnull(cell_val): return wagons, load_type
Â  Â  s = str(cell_val).strip().upper()
Â  Â  match_num = re.search(r'(\d{2})', s)
Â  Â  if match_num:
Â  Â  Â  Â  try: wagons = int(match_num.group(1))
Â  Â  Â  Â  except: pass
Â  Â  if 'R' in s: load_type = 'BOBR'
Â  Â  elif 'N' in s: load_type = 'BOXN'
Â  Â  return wagons, load_type

def classify_reason(reason_text):
Â  Â  if not reason_text: return "Misc"
Â  Â  txt = reason_text.upper()
Â  Â Â 
Â  Â  mm_keys = ['MM', 'MECH', 'BELT', 'ROLL', 'IDLER', 'LINER', 'CHUTE', 'GEAR', 'BEARING', 'PULLEY']
Â  Â  emd_keys = ['EMD', 'ELEC', 'MOTOR', 'POWER', 'SUPPLY', 'CABLE', 'TRIP', 'FUSE']
Â  Â  cni_keys = ['C&I', 'CNI', 'SENSOR', 'PROBE', 'SIGNAL', 'PLC', 'COMM', 'ZERO']
Â  Â  rs_keys = ['C&W', 'WAGON', 'DOOR', 'COUPL', 'RAKE']
Â  Â  mgr_keys = ['MGR', 'TRACK', 'LOCO', 'DERAIL', 'SLEEPER']
Â  Â  chem_keys = ['CHEM', 'LAB', 'QUALITY', 'SAMPLE', 'ASH', 'MOISTURE']
Â  Â  opr_keys = ['OPR', 'OPER', 'CREW', 'SHIFT', 'MANPOWER', 'BUNKER', 'FULL', 'WAIT']

Â  Â  if any(k in txt for k in mm_keys): return "MM"
Â  Â  if any(k in txt for k in emd_keys): return "EMD"
Â  Â  if any(k in txt for k in cni_keys): return "C&I"
Â  Â  if any(k in txt for k in rs_keys): return "Rolling Stock"
Â  Â  if any(k in txt for k in mgr_keys): return "MGR"
Â  Â  if any(k in txt for k in chem_keys): return "Chemistry"
Â  Â  if any(k in txt for k in opr_keys): return "OPR"
Â  Â Â 
Â  Â  return "Misc"

def parse_demurrage_special(cell_val):
Â  Â  s = str(cell_val).strip().upper()
Â  Â  if s in ["", "NAN", "NIL", "-", "NONE"]: return "00:00"
Â  Â  if ":" in s:
Â  Â  Â  Â  if re.search(r'\d+:\d+', s): return s
Â  Â  match = re.search(r'(\d+(\.\d+)?)', s)
Â  Â  if match:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  val = float(match.group(1))
Â  Â  Â  Â  Â  Â  hours = int(val)
Â  Â  Â  Â  Â  Â  minutes = int((val - hours) * 60)
Â  Â  Â  Â  Â  Â  return f"{hours:02d}:{minutes:02d}"
Â  Â  Â  Â  except: pass
Â  Â  return "00:00"

# ==========================================
# 3. GOOGLE SHEET PARSER (ALL DATA)
# ==========================================

def safe_parse_date(val):
Â  Â  if pd.isnull(val) or str(val).strip() == "" or str(val).strip().upper() == "U/P": return pd.NaT
Â  Â  try:
Â  Â  Â  Â  dt = pd.to_datetime(val, dayfirst=True, errors='coerce')Â 
Â  Â  Â  Â  if pd.isnull(dt): return pd.NaTÂ 
Â  Â  Â  Â  return to_ist(dt)
Â  Â  except: return pd.NaT

@st.cache_data(ttl=60)
def fetch_google_sheet_actuals(url, free_time_hours):
Â  Â  try:
Â  Â  Â  Â  df_gs = pd.read_csv(url, header=None, skiprows=1)Â 
Â  Â  Â  Â  if len(df_gs.columns) < 18: return pd.DataFrame(), pd.DataFrame(), (0,0)

Â  Â  Â  Â  locked_actuals = []
Â  Â  Â  Â  unplanned_actuals = []Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  last_seq_tuple = (0, 0)

Â  Â  Â  Â  for i in range(len(df_gs)):
Â  Â  Â  Â  Â  Â  row = df_gs.iloc[i]
Â  Â  Â  Â  Â  Â  val_b = str(row.iloc[1]).strip()
Â  Â  Â  Â  Â  Â  val_c = str(row.iloc[2]).strip()
Â  Â  Â  Â  Â  Â  if not val_b or val_b.lower() == 'nan': continueÂ 
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  source_val = "Unknown" if (not val_c or val_c.lower() == 'nan') else val_c
Â  Â  Â  Â  Â  Â  arrival_dt = safe_parse_date(row.iloc[4])Â 
Â  Â  Â  Â  Â  Â  if pd.isnull(arrival_dt): continue
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  dept_val = str(row.iloc[11]).strip()
Â  Â  Â  Â  Â  Â  if dept_val.lower() in ['nan', '', 'none']: dept_val = ""
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  reason_detail = ""
Â  Â  Â  Â  Â  Â  if i + 1 < len(df_gs):
Â  Â  Â  Â  Â  Â  Â  Â  next_row = df_gs.iloc[i + 1]
Â  Â  Â  Â  Â  Â  Â  Â  next_rake_name = str(next_row.iloc[1]).strip()
Â  Â  Â  Â  Â  Â  Â  Â  if not next_rake_name or next_rake_name.lower() == 'nan':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  reason_val = str(next_row.iloc[11]).strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if reason_val.lower() not in ['nan', '', 'none']:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  reason_detail = reason_val
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if dept_val and reason_detail:
Â  Â  Â  Â  Â  Â  Â  Â  full_remarks_blob = f"{dept_val}|{reason_detail}"
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  full_remarks_blob = ""

Â  Â  Â  Â  Â  Â  rake_name = val_b
Â  Â  Â  Â  Â  Â  col_d_val = row.iloc[3]
Â  Â  Â  Â  Â  Â  wagons, load_type = parse_col_d_wagon_type(col_d_val)

Â  Â  Â  Â  Â  Â  start_dt = safe_parse_date(row.iloc[5])
Â  Â  Â  Â  Â  Â  end_dt = safe_parse_date(row.iloc[6])
Â  Â  Â  Â  Â  Â  if pd.isnull(start_dt): start_dt = arrival_dtÂ 
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  tippler_timings = {}
Â  Â  Â  Â  Â  Â  active_tipplers_row = []
Â  Â  Â  Â  Â  Â  explicit_wagon_counts = {}
Â  Â  Â  Â  Â  Â  tippler_objs = {} # Store Date Objects

Â  Â  Â  Â  Â  Â  for t_name, idx in [('T1', 14), ('T2', 15), ('T3', 16), ('T4', 17)]:
Â  Â  Â  Â  Â  Â  Â  Â  cell_val = row.iloc[idx]
Â  Â  Â  Â  Â  Â  Â  Â  if pd.notnull(cell_val) and str(cell_val).strip() not in ["", "nan"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  wc = parse_wagon_count_from_cell(cell_val)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ts, te = parse_tippler_cell(cell_val, arrival_dt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.isnull(ts) and wc is not None:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.notnull(start_dt):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ts = start_dt
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  te = end_dt if pd.notnull(end_dt) else start_dt + timedelta(hours=2)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif pd.isnull(ts) and pd.notnull(start_dt):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pass

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.notnull(ts):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  active_tipplers_row.append(t_name)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tippler_timings[f"{t_name} Start"] = format_dt(ts)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tippler_timings[f"{t_name} End"] = format_dt(te)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tippler_timings[f"{t_name}_Obj_End"] = te
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # SAVE REAL DATETIME OBJECTS
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tippler_objs[f"{t_name}_Start_Obj"] = ts
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tippler_objs[f"{t_name}_End_Obj"] = te
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if wc is not None: explicit_wagon_counts[t_name] = wc

Â  Â  Â  Â  Â  Â  is_unplanned = (not active_tipplers_row and load_type != 'BOBR')
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  seq, rid = parse_last_sequence(rake_name)
Â  Â  Â  Â  Â  Â  if seq > last_seq_tuple[0] or (seq == last_seq_tuple[0] and rid > last_seq_tuple[1]):
Â  Â  Â  Â  Â  Â  Â  Â  last_seq_tuple = (seq, rid)

Â  Â  Â  Â  Â  Â  if is_unplanned:
Â  Â  Â  Â  Â  Â  Â  Â  unplanned_actuals.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Rake': rake_name,Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Coal Source': source_val,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Load Type': load_type,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Wagons': wagons,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Status': 'Pending (G-Sheet)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '_Arrival_DT': arrival_dt,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '_Form_Mins': 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Optimization Type': 'Auto-Planned (G-Sheet)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Extra Shunt (Mins)': 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'is_gs_unplanned': True,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '_remarks': full_remarks_blob
Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  Â  Â  continueÂ 

Â  Â  Â  Â  Â  Â  t_str_list = []
Â  Â  Â  Â  Â  Â  wagon_counts_map = {}
Â  Â  Â  Â  Â  Â  if explicit_wagon_counts:
Â  Â  Â  Â  Â  Â  Â  Â  for t in active_tipplers_row:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cnt = explicit_wagon_counts.get(t, 0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  t_str_list.append(f"{t} ({cnt})")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  wagon_counts_map[f"{t}_Wagons"] = cnt
Â  Â  Â  Â  Â  Â  elif len(active_tipplers_row) > 0:
Â  Â  Â  Â  Â  Â  Â  Â  share = wagons // len(active_tipplers_row)
Â  Â  Â  Â  Â  Â  Â  Â  rem = wagons % len(active_tipplers_row)
Â  Â  Â  Â  Â  Â  Â  Â  for i, t in enumerate(active_tipplers_row):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cnt = share + (1 if i < rem else 0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  t_str_list.append(f"{t} ({cnt})")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  wagon_counts_map[f"{t}_Wagons"] = cnt
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  used_tipplers_str = ", ".join(t_str_list)

Â  Â  Â  Â  Â  Â  raw_dur = row.iloc[8]
Â  Â  Â  Â  Â  Â  total_dur = timedelta(0)
Â  Â  Â  Â  Â  Â  if pd.notnull(raw_dur):
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if ":" in str(raw_dur):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parts = str(raw_dur).split(":")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  total_dur = timedelta(hours=int(parts[0]), minutes=int(parts[1]))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: total_dur = timedelta(days=float(raw_dur))
Â  Â  Â  Â  Â  Â  Â  Â  except:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.notnull(safe_parse_date(row.iloc[7])):Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  total_dur = safe_parse_date(row.iloc[7]) - arrival_dt

Â  Â  Â  Â  Â  Â  raw_dem_val = row.iloc[10]
Â  Â  Â  Â  Â  Â  dem_str = parse_demurrage_special(raw_dem_val)

Â  Â  Â  Â  Â  Â  entry = {
Â  Â  Â  Â  Â  Â  Â  Â  'Rake': rake_name,
Â  Â  Â  Â  Â  Â  Â  Â  'Coal Source': source_val,
Â  Â  Â  Â  Â  Â  Â  Â  'Load Type': load_type,
Â  Â  Â  Â  Â  Â  Â  Â  'Wagons': wagons,
Â  Â  Â  Â  Â  Â  Â  Â  'Status': 'ACTUAL',
Â  Â  Â  Â  Â  Â  Â  Â  '_Arrival_DT': arrival_dt,
Â  Â  Â  Â  Â  Â  Â  Â  '_Shunt_Ready_DT': start_dt,
Â  Â  Â  Â  Â  Â  Â  Â  '_Form_Mins': 0,
Â  Â  Â  Â  Â  Â  Â  Â  'Optimization Type': 'Actual (G-Sheet)',
Â  Â  Â  Â  Â  Â  Â  Â  'Extra Shunt (Mins)': 0,
Â  Â  Â  Â  Â  Â  Â  Â  'Line Allotted': 'N/A',
Â  Â  Â  Â  Â  Â  Â  Â  'Line Entry Time': format_dt(arrival_dt),
Â  Â  Â  Â  Â  Â  Â  Â  'Shunting Complete': format_dt(start_dt),
Â  Â  Â  Â  Â  Â  Â  Â  'Tippler Start Time': format_dt(start_dt),
Â  Â  Â  Â  Â  Â  Â  Â  'Finish Unload': format_dt(end_dt),
Â  Â  Â  Â  Â  Â  Â  Â  'Tipplers Used': used_tipplers_str,
Â  Â  Â  Â  Â  Â  Â  Â  'Wait (Tippler)': format_duration_hhmm(start_dt - arrival_dt) if pd.notnull(start_dt) else "",
Â  Â  Â  Â  Â  Â  Â  Â  'Total Duration': format_duration_hhmm(total_dur),
Â  Â  Â  Â  Â  Â  Â  Â  'Demurrage': dem_str,
Â  Â  Â  Â  Â  Â  Â  Â  '_raw_end_dt': end_dt,
Â  Â  Â  Â  Â  Â  Â  Â  '_raw_tipplers_data': tippler_timings,
Â  Â  Â  Â  Â  Â  Â  Â  '_raw_wagon_counts': wagon_counts_map,
Â  Â  Â  Â  Â  Â  Â  Â  '_raw_tipplers': active_tipplers_row,
Â  Â  Â  Â  Â  Â  Â  Â  '_remarks': full_remarks_blob
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  # INJECT HIDDEN OBJECTS
Â  Â  Â  Â  Â  Â  for t, obj in tippler_objs.items():
Â  Â  Â  Â  Â  Â  Â  Â  entry[t] = obj # e.g. T1_Start_Obj

Â  Â  Â  Â  Â  Â  for t in ['T1', 'T2', 'T3', 'T4']:
Â  Â  Â  Â  Â  Â  Â  Â  entry[f"{t} Start"] = tippler_timings.get(f"{t} Start", "")
Â  Â  Â  Â  Â  Â  Â  Â  entry[f"{t} End"] = tippler_timings.get(f"{t} End", "")
Â  Â  Â  Â  Â  Â  Â  Â  entry[f"{t} Idle"] = ""
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  locked_actuals.append(entry)

Â  Â  Â  Â  return pd.DataFrame(locked_actuals), pd.DataFrame(unplanned_actuals), last_seq_tuple

Â  Â  except Exception as e:
Â  Â  Â  Â  return pd.DataFrame(), pd.DataFrame(), (0,0)

# ==========================================
# 4. CORE SIMULATION LOGIC
# ==========================================

def calculate_generic_finish(wagons, target_tipplers, ready_time, tippler_state, downtime_list,Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â rates, wagons_first_batch, inter_tippler_delay):
Â  Â  if wagons == 0: return ready_time, "", ready_time, {}, timedelta(0), {}
Â  Â Â 
Â  Â  candidates = []
Â  Â  for t in target_tipplers:
Â  Â  Â  Â  free_at = tippler_state[t]
Â  Â  Â  Â  if free_at.tzinfo is None: free_at = IST.localize(free_at)
Â  Â  Â  Â  prop_start = max(ready_time, free_at)
Â  Â  Â  Â  effective_start = check_downtime_impact(t, prop_start, downtime_list)
Â  Â  Â  Â  pred_finish = effective_start + timedelta(hours=wagons / rates[t])
Â  Â  Â  Â  candidates.append({'id': t, 'rate': rates[t], 'eff_start': effective_start, 'free_at': free_at, 'pred_fin': pred_finish})
Â  Â Â 
Â  Â  candidates.sort(key=lambda x: x['pred_fin'])
Â  Â  best_solo = candidates[0]
Â  Â Â 
Â  Â  finish_A = best_solo['pred_fin']
Â  Â  used_list_str = [f"{best_solo['id']} ({wagons})"]
Â  Â  wagon_counts = {f"{best_solo['id']}_Wagons": wagons}
Â  Â Â 
Â  Â  final_timings = {
Â  Â  Â  Â  f"{best_solo['id']}_Start": best_solo['eff_start'],
Â  Â  Â  Â  f"{best_solo['id']}_End": best_solo['pred_fin'],
Â  Â  Â  Â  f"{best_solo['id']}_Idle": max(timedelta(0), best_solo['eff_start'] - best_solo['free_at'])
Â  Â  }
Â  Â  actual_start = best_solo['eff_start']

Â  Â  if len(candidates) > 1 and wagons > wagons_first_batch:
Â  Â  Â  Â  prim = candidates[0]
Â  Â  Â  Â  sec = candidates[1]
Â  Â  Â  Â  w_first = wagons_first_batch
Â  Â  Â  Â  w_second = wagons - w_first
Â  Â  Â  Â  fin_prim_split = prim['eff_start'] + timedelta(hours=w_first / prim['rate'])
Â  Â  Â  Â  sec_ready_theory = ready_time + timedelta(minutes=inter_tippler_delay)
Â  Â  Â  Â  prop_start_sec = max(sec_ready_theory, sec['free_at'])
Â  Â  Â  Â  real_start_sec = check_downtime_impact(sec['id'], prop_start_sec, downtime_list)
Â  Â  Â  Â  fin_sec_split = real_start_sec + timedelta(hours=w_second / sec['rate'])
Â  Â  Â  Â  finish_pair = max(fin_prim_split, fin_sec_split)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if finish_pair < finish_A:
Â  Â  Â  Â  Â  Â  finish_A = finish_pair
Â  Â  Â  Â  Â  Â  ts = [(prim['id'], w_first), (sec['id'], w_second)]
Â  Â  Â  Â  Â  Â  ts.sort(key=lambda x: x[0])
Â  Â  Â  Â  Â  Â  used_list_str = [f"{x[0]} ({x[1]})" for x in ts]
Â  Â  Â  Â  Â  Â  wagon_counts = {f"{prim['id']}_Wagons": w_first, f"{sec['id']}_Wagons": w_second}
Â  Â  Â  Â  Â  Â  actual_start = prim['eff_start']
Â  Â  Â  Â  Â  Â  final_timings = {}
Â  Â  Â  Â  Â  Â  final_timings[f"{prim['id']}_Start"] = prim['eff_start']
Â  Â  Â  Â  Â  Â  final_timings[f"{prim['id']}_End"] = fin_prim_split
Â  Â  Â  Â  Â  Â  final_timings[f"{prim['id']}_Idle"] = max(timedelta(0), prim['eff_start'] - prim['free_at'])
Â  Â  Â  Â  Â  Â  final_timings[f"{sec['id']}_Start"] = real_start_sec
Â  Â  Â  Â  Â  Â  final_timings[f"{sec['id']}_End"] = fin_sec_split
Â  Â  Â  Â  Â  Â  final_timings[f"{sec['id']}_Idle"] = max(timedelta(0), real_start_sec - sec['free_at'])

Â  Â  return finish_A, ", ".join(used_list_str), actual_start, final_timings, timedelta(0), wagon_counts

def get_line_entry_time(group, arrival, line_groups):
Â  Â  grp = line_groups[group]
Â  Â  active = sorted([t for t in grp['line_free_times'] if t > arrival])
Â  Â  if len(active) < grp['capacity']: return arrival
Â  Â  return active[len(active) - grp['capacity']]

def run_full_simulation_initial(df_csv, params, df_locked, df_unplanned, last_seq_tuple):
Â  Â  rates = {'T1': params['rt1'], 'T2': params['rt2'], 'T3': params['rt3'], 'T4': params['rt4']}
Â  Â  s_a, s_b, extra_shunt_cross = params['sa'], params['sb'], params['extra_shunt']
Â  Â  f_a, f_b, ft_hours = params['fa'], params['fb'], params['ft']
Â  Â  w_batch, w_delay, downtimes = params['wb'], params['wd'], params['downtimes']

Â  Â  to_plan = []
Â  Â Â 
Â  Â  if not df_unplanned.empty:
Â  Â  Â  Â  for _, row in df_unplanned.iterrows():
Â  Â  Â  Â  Â  Â  to_plan.append(row.to_dict())

Â  Â  if not df_csv.empty:
Â  Â  Â  Â  df = df_csv.copy()
Â  Â  Â  Â  load_col = find_column(df, ['LOAD TYPE', 'CMDT', 'COMMODITY'])
Â  Â  Â  Â  if load_col:
Â  Â  Â  Â  Â  Â  df = df[df[load_col].astype(str).str.upper().str.contains('BOXN|BOBR', regex=True, na=False)]
Â  Â  Â  Â  wagon_col = find_column(df, ['TOTL UNTS', 'WAGONS', 'UNITS', 'TOTAL UNITS'])
Â  Â  Â  Â  if wagon_col: df['wagon_count'] = df[wagon_col].apply(parse_wagons)
Â  Â  Â  Â  else: df['wagon_count'] = 58Â 
Â  Â  Â  Â  src_col = find_column(df, ['STTS FROM', 'STTN FROM', 'FROM_STN', 'SRC', 'SOURCE', 'FROM'])
Â  Â  Â  Â  arvl_col = find_column(df, ['EXPD ARVLTIME', 'ARRIVAL TIME', 'EXPECTED ARRIVAL'])
Â  Â  Â  Â  stts_time_col = find_column(df, ['STTS TIME'])
Â  Â  Â  Â  stts_code_col = find_column(df, ['STTS CODE', 'STATUS'])

Â  Â  Â  Â  if arvl_col:
Â  Â  Â  Â  Â  Â  df['exp_arrival_dt'] = pd.to_datetime(df[arvl_col], errors='coerce').apply(to_ist) if arvl_col else pd.NaT
Â  Â  Â  Â  Â  Â  if stts_time_col and stts_code_col:
Â  Â  Â  Â  Â  Â  Â  Â  df['stts_time_dt'] = pd.to_datetime(df[stts_time_col], errors='coerce').apply(to_ist)
Â  Â  Â  Â  Â  Â  Â  Â  df['arrival_dt'] = df.apply(lambda r: r['stts_time_dt'] if str(r.get(stts_code_col)).strip()=='PL' and pd.notnull(r['stts_time_dt']) else r['exp_arrival_dt'], axis=1)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  df['arrival_dt'] = df['exp_arrival_dt']
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  df = df.dropna(subset=['arrival_dt']).sort_values('arrival_dt')

Â  Â  Â  Â  Â  Â  existing_times = set()
Â  Â  Â  Â  Â  Â  if not df_locked.empty: existing_times.update(df_locked['_Arrival_DT'].dt.floor('min'))
Â  Â  Â  Â  Â  Â  if not df_unplanned.empty: existing_times.update(df_unplanned['_Arrival_DT'].dt.floor('min'))

Â  Â  Â  Â  Â  Â  for _, row in df.iterrows():
Â  Â  Â  Â  Â  Â  Â  Â  if row['arrival_dt'].floor('min') in existing_times: continueÂ 
Â  Â  Â  Â  Â  Â  Â  Â  l_type = row.get(load_col, 'BOXN') if load_col else 'BOXN'
Â  Â  Â  Â  Â  Â  Â  Â  to_plan.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Coal Source': row.get(src_col, '') if src_col else '',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Load Type': l_type,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Wagons': row['wagon_count'],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Status': row.get(stts_code_col, 'N/A') if stts_code_col else 'N/A',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '_Arrival_DT': row['arrival_dt'],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '_Form_Mins': 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Optimization Type': 'Forecast',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Extra Shunt (Mins)': 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'is_csv': TrueÂ 
Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  plan_df = pd.DataFrame(to_plan)
Â  Â  if plan_df.empty and df_locked.empty: return pd.DataFrame(), pd.DataFrame(), datetime.now(IST)
Â  Â Â 
Â  Â  if not plan_df.empty:
Â  Â  Â  Â  plan_df = plan_df.sort_values('_Arrival_DT').reset_index(drop=True)
Â  Â  Â  Â  first_arrival = plan_df['_Arrival_DT'].min()
Â  Â  else:
Â  Â  Â  Â  first_arrival = datetime.now(IST)

Â  Â  sim_start_time = first_arrival.replace(hour=0, minute=0, second=0, microsecond=0)
Â  Â  if sim_start_time.tzinfo is None: sim_start_time = IST.localize(sim_start_time)

Â  Â  tippler_state = {k: sim_start_time for k in ['T1', 'T2', 'T3', 'T4']}
Â  Â  if not df_locked.empty:
Â  Â  Â  Â  for _, row in df_locked.iterrows():
Â  Â  Â  Â  Â  Â  raw_t_data = row.get('_raw_tipplers_data', {})
Â  Â  Â  Â  Â  Â  parsed_found = False
Â  Â  Â  Â  Â  Â  for t in ['T1', 'T2', 'T3', 'T4']:
Â  Â  Â  Â  Â  Â  Â  Â  t_end_obj = raw_t_data.get(f"{t}_Obj_End")
Â  Â  Â  Â  Â  Â  Â  Â  if pd.notnull(t_end_obj):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if t_end_obj > tippler_state[t]: tippler_state[t] = t_end_obj
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parsed_found = True
Â  Â  Â  Â  Â  Â  if not parsed_found:
Â  Â  Â  Â  Â  Â  Â  Â  if '_raw_tipplers' in row:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  used_list = row['_raw_tipplers']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  end_val = row['_raw_end_dt']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.notnull(end_val) and isinstance(used_list, list):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for t in ['T1', 'T2', 'T3', 'T4']:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if t in used_list and end_val > tippler_state[t]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tippler_state[t] = end_val

Â  Â  line_groups = {
Â  Â  Â  Â  'Group_Lines_8_10': {'capacity': 2, 'clearance_mins': 50, 'line_free_times': []},
Â  Â  Â  Â  'Group_Line_11': {'capacity': 1, 'clearance_mins': 100, 'line_free_times': []}
Â  Â  }
Â  Â Â 
Â  Â  curr_seq = last_seq_tuple[0]
Â  Â  curr_id = last_seq_tuple[1]
Â  Â  assignments = []

Â  Â  for _, rake in plan_df.iterrows():
Â  Â  Â  Â  orig_name = str(rake.get('Rake', ''))
Â  Â  Â  Â  is_gs = rake.get('is_gs_unplanned', False)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if is_gs and '/' in orig_name:
Â  Â  Â  Â  Â  Â  display_name = orig_name
Â  Â  Â  Â  Â  Â  s, i = parse_last_sequence(display_name)
Â  Â  Â  Â  Â  Â  if s > 0: curr_seq, curr_id = s, i
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  curr_seq += 1
Â  Â  Â  Â  Â  Â  curr_id += 1
Â  Â  Â  Â  Â  Â  display_name = f"{curr_seq}/{curr_id}"
Â  Â  Â  Â Â 
Â  Â  Â  Â  is_bobr = 'BOBR' in str(rake['Load Type']).upper()

Â  Â  Â  Â  if is_bobr:
Â  Â  Â  Â  Â  Â  row_data = {
Â  Â  Â  Â  Â  Â  Â  Â  'Rake': display_name,
Â  Â  Â  Â  Â  Â  Â  Â  'Coal Source': rake['Coal Source'],
Â  Â  Â  Â  Â  Â  Â  Â  'Load Type': rake['Load Type'],
Â  Â  Â  Â  Â  Â  Â  Â  'Wagons': rake['Wagons'],
Â  Â  Â  Â  Â  Â  Â  Â  'Status': rake['Status'],
Â  Â  Â  Â  Â  Â  Â  Â  '_Arrival_DT': rake['_Arrival_DT'],
Â  Â  Â  Â  Â  Â  Â  Â  '_Shunt_Ready_DT': pd.NaT,
Â  Â  Â  Â  Â  Â  Â  Â  '_Form_Mins': 0,
Â  Â  Â  Â  Â  Â  Â  Â  'Optimization Type': 'BOBR (No Tippler)',
Â  Â  Â  Â  Â  Â  Â  Â  'Extra Shunt (Mins)': 0,
Â  Â  Â  Â  Â  Â  Â  Â  'Line Allotted': 'N/A',
Â  Â  Â  Â  Â  Â  Â  Â  'Line Entry Time': format_dt(rake['_Arrival_DT']),
Â  Â  Â  Â  Â  Â  Â  Â  'Shunting Complete': "",
Â  Â  Â  Â  Â  Â  Â  Â  'Tippler Start Time': "",
Â  Â  Â  Â  Â  Â  Â  Â  'Finish Unload': "",
Â  Â  Â  Â  Â  Â  Â  Â  'Tipplers Used': "N/A",
Â  Â  Â  Â  Â  Â  Â  Â  'Wait (Tippler)': "",
Â  Â  Â  Â  Â  Â  Â  Â  'Total Duration': "",
Â  Â  Â  Â  Â  Â  Â  Â  'Demurrage': "00:00",
Â  Â  Â  Â  Â  Â  Â  Â  '_raw_wagon_counts': {},
Â  Â  Â  Â  Â  Â  Â  Â  '_remarks': ""
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  for t in ['T1', 'T2', 'T3', 'T4']:
Â  Â  Â  Â  Â  Â  Â  Â  Â row_data[f"{t} Start"] = ""; row_data[f"{t} End"] = ""; row_data[f"{t} Idle"] = ""
Â  Â  Â  Â  Â  Â  assignments.append(row_data)
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  entry_A = get_line_entry_time('Group_Lines_8_10', rake['_Arrival_DT'], line_groups)
Â  Â  Â  Â  ready_A = entry_A + timedelta(minutes=s_a)
Â  Â  Â  Â  fin_A, used_A, start_A, tim_A, _, wag_A = calculate_generic_finish(
Â  Â  Â  Â  Â  Â  rake['Wagons'], ['T1', 'T2'], ready_A, tippler_state, downtimes, rates, w_batch, w_delay)
Â  Â  Â  Â Â 
Â  Â  Â  Â  entry_B = get_line_entry_time('Group_Line_11', rake['_Arrival_DT'], line_groups)
Â  Â  Â  Â  ready_B = entry_B + timedelta(minutes=s_b)
Â  Â  Â  Â  fin_B, used_B, start_B, tim_B, _, wag_B = calculate_generic_finish(
Â  Â  Â  Â  Â  Â  rake['Wagons'], ['T3', 'T4'], ready_B, tippler_state, downtimes, rates, w_batch, w_delay)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if fin_B < fin_A:
Â  Â  Â  Â  Â  Â  best_fin, best_used, best_start, best_timings, best_entry, best_ready = fin_B, used_B, start_B, tim_B, entry_B, ready_B
Â  Â  Â  Â  Â  Â  best_grp, best_line, best_wag = 'Group_Line_11', '11', wag_B
Â  Â  Â  Â  Â  Â  best_type = "Standard (Fast)"
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  best_fin, best_used, best_start, best_timings, best_entry, best_ready = fin_A, used_A, start_A, tim_A, entry_A, ready_A
Â  Â  Â  Â  Â  Â  best_grp, best_line, best_wag = 'Group_Lines_8_10', '8/9/10', wag_A
Â  Â  Â  Â  Â  Â  best_type = "Standard"

Â  Â  Â  Â  for k, v in best_timings.items():
Â  Â  Â  Â  Â  Â  if 'End' in k: tippler_state[k.split('_')[0]] = v
Â  Â  Â  Â  if best_grp == 'Group_Lines_8_10':
Â  Â  Â  Â  Â  Â  Â line_groups['Group_Lines_8_10']['line_free_times'].append(best_entry + timedelta(minutes=50))

Â  Â  Â  Â  release_time = best_fin + timedelta(minutes=f_a)
Â  Â  Â  Â  tot_dur_final = release_time - rake['_Arrival_DT']
Â  Â  Â  Â  dem_str, _ = calculate_rounded_demurrage(tot_dur_final, ft_hours)

Â  Â  Â  Â  row_data = {
Â  Â  Â  Â  Â  Â  'Rake': display_name,
Â  Â  Â  Â  Â  Â  'Coal Source': rake['Coal Source'],
Â  Â  Â  Â  Â  Â  'Load Type': rake['Load Type'],
Â  Â  Â  Â  Â  Â  'Wagons': rake['Wagons'],
Â  Â  Â  Â  Â  Â  'Status': rake['Status'],
Â  Â  Â  Â  Â  Â  '_Arrival_DT': rake['_Arrival_DT'],
Â  Â  Â  Â  Â  Â  '_Shunt_Ready_DT': best_ready,
Â  Â  Â  Â  Â  Â  '_Form_Mins': f_a,
Â  Â  Â  Â  Â  Â  'Optimization Type': best_type,
Â  Â  Â  Â  Â  Â  'Extra Shunt (Mins)': 0,
Â  Â  Â  Â  Â  Â  'Line Allotted': best_line,
Â  Â  Â  Â  Â  Â  'Line Entry Time': format_dt(best_entry),
Â  Â  Â  Â  Â  Â  'Shunting Complete': format_dt(best_ready),
Â  Â  Â  Â  Â  Â  'Tippler Start Time': format_dt(best_start),
Â  Â  Â  Â  Â  Â  'Finish Unload': format_dt(best_fin),
Â  Â  Â  Â  Â  Â  'Tipplers Used': best_used,
Â  Â  Â  Â  Â  Â  'Wait (Tippler)': format_duration_hhmm(best_start - best_ready),
Â  Â  Â  Â  Â  Â  'Total Duration': format_duration_hhmm(tot_dur_final),
Â  Â  Â  Â  Â  Â  'Demurrage': dem_str,
Â  Â  Â  Â  Â  Â  '_raw_wagon_counts': best_wag,
Â  Â  Â  Â  Â  Â  '_remarks': rake.get('_remarks', "")
Â  Â  Â  Â  }
Â  Â  Â  Â  for t in ['T1', 'T2', 'T3', 'T4']:
Â  Â  Â  Â  Â  Â  Â row_data[f"{t} Start"] = format_dt(best_timings.get(f"{t}_Start", pd.NaT))
Â  Â  Â  Â  Â  Â  Â row_data[f"{t} End"] = format_dt(best_timings.get(f"{t}_End", pd.NaT))
Â  Â  Â  Â  Â  Â  Â row_data[f"{t} Idle"] = format_duration_hhmm(best_timings.get(f"{t}_Idle", pd.NaT))
Â  Â  Â  Â  assignments.append(row_data)

Â  Â  df_sim = pd.DataFrame(assignments)
Â  Â Â 
Â  Â  if not df_locked.empty:
Â  Â  Â  Â  today_date = datetime.now(IST).date()
Â  Â  Â  Â  yesterday_date = today_date - timedelta(days=1)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # VISUAL FILTER (TAB 1 ONLY)
Â  Â  Â  Â  def keep_row(r):
Â  Â  Â  Â  Â  Â  ad = r['_Arrival_DT'].date()
Â  Â  Â  Â  Â  Â  if ad >= yesterday_date: return True
Â  Â  Â  Â  Â  Â  return FalseÂ 
Â  Â  Â  Â  df_locked_visible = df_locked[df_locked.apply(keep_row, axis=1)]
Â  Â  Â  Â Â 
Â  Â  Â  Â  cols_to_drop = ['_raw_tipplers_data', '_raw_end_dt', '_raw_tipplers'] + [f"{t}_{x}_Obj" for t in ['T1','T2','T3','T4'] for x in ['Start','End']]
Â  Â  Â  Â  actuals_clean = df_locked_visible.drop(columns=[c for c in cols_to_drop if c in df_locked_visible.columns], errors='ignore')
Â  Â  Â  Â Â 
Â  Â  Â  Â  final_df_display = pd.concat([actuals_clean, df_sim], ignore_index=True) if not df_sim.empty else actuals_clean
Â  Â  Â  Â  # FIXED: DO NOT DROP '_Obj' COLUMNS HERE FOR TAB 2
Â  Â  Â  Â  final_df_all = pd.concat([df_locked, df_sim], ignore_index=True)
Â  Â  else:
Â  Â  Â  Â  final_df_display = df_sim
Â  Â  Â  Â  final_df_all = df_sim

Â  Â  return final_df_display, final_df_all, sim_start_time

def recalculate_cascade_reactive(df_all, start_filter_dt=None, end_filter_dt=None):
Â  Â  daily_stats = {}Â 
Â  Â Â 
Â  Â  for _, row in df_all.iterrows():
Â  Â  Â  Â  dem_val = str(row['Demurrage']).strip()
Â  Â  Â  Â  dem_hrs = 0
Â  Â  Â  Â  if ":" in dem_val: dem_hrs = int(dem_val.split(":")[0])
Â  Â  Â  Â  elif dem_val.isdigit(): dem_hrs = int(dem_val)
Â  Â  Â  Â Â 
Â  Â  Â  Â  arr_dt = pd.to_datetime(row['_Arrival_DT'])
Â  Â  Â  Â  if arr_dt.tzinfo is None: arr_dt = IST.localize(arr_dt)
Â  Â  Â  Â  d_str = arr_dt.strftime('%Y-%m-%d')
Â  Â  Â  Â Â 
Â  Â  Â  Â  if start_filter_dt and arr_dt.date() < start_filter_dt: continue
Â  Â  Â  Â  if end_filter_dt and arr_dt.date() > end_filter_dt: continue

Â  Â  Â  Â  if d_str not in daily_stats:Â 
Â  Â  Â  Â  Â  Â  daily_stats[d_str] = {'Demurrage': 0, 'All_Reasons': set()}
Â  Â  Â  Â  Â  Â  for t in ['T1', 'T2', 'T3', 'T4']:Â 
Â  Â  Â  Â  Â  Â  Â  Â  daily_stats[d_str][f'{t}_hrs'] = 0.0
Â  Â  Â  Â  Â  Â  Â  Â  daily_stats[d_str][f'{t}_wag'] = 0.0
Â  Â  Â  Â Â 
Â  Â  Â  Â  daily_stats[d_str]['Demurrage'] += dem_hrs
Â  Â  Â  Â Â 
Â  Â  Â  Â  if dem_hrs > 0:
Â  Â  Â  Â  Â  Â  rem = str(row.get('_remarks', '')).strip()
Â  Â  Â  Â  Â  Â  rake_name = str(row.get('Rake', 'Unknown'))
Â  Â  Â  Â  Â  Â  if '|' in rem:
Â  Â  Â  Â  Â  Â  Â  Â  dept_part, reason_part = rem.split('|', 1)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  dept_part, reason_part = rem, ""
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if dept_part:
Â  Â  Â  Â  Â  Â  Â  Â  dept_code = classify_reason(dept_part)
Â  Â  Â  Â  Â  Â  Â  Â  final_text = reason_part if reason_part else dept_part
Â  Â  Â  Â  Â  Â  Â  Â  formatted_reason = f"[{rake_name}] - {final_text} ({dept_code})"
Â  Â  Â  Â  Â  Â  Â  Â  daily_stats[d_str]['All_Reasons'].add(formatted_reason)
Â  Â  Â  Â Â 
Â  Â  Â  Â  wag_map = row.get('_raw_wagon_counts', {})
Â  Â  Â  Â  if not isinstance(wag_map, dict): wag_map = {}
Â  Â  Â  Â Â 
Â  Â  Â  Â  for t in ['T1', 'T2', 'T3', 'T4']:
Â  Â  Â  Â  Â  Â  # SMART DATE HANDLING (FIX FOR PAST DATES)
Â  Â  Â  Â  Â  Â  s_dt = row.get(f"{t}_Start_Obj", pd.NaT)
Â  Â  Â  Â  Â  Â  e_dt = row.get(f"{t}_End_Obj", pd.NaT)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if pd.isnull(s_dt) or pd.isnull(e_dt):
Â  Â  Â  Â  Â  Â  Â  Â  # Fallback: Parse string using ARRIVAL DATE context
Â  Â  Â  Â  Â  Â  Â  Â  start_str = str(row.get(f"{t} Start", ""))
Â  Â  Â  Â  Â  Â  Â  Â  end_str = str(row.get(f"{t} End", ""))
Â  Â  Â  Â  Â  Â  Â  Â  if start_str and end_str:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  s_dt = parse_dt_from_str_smart(start_str, arr_dt)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  e_dt = parse_dt_from_str_smart(end_str, arr_dt)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if pd.notnull(s_dt) and pd.notnull(e_dt):
Â  Â  Â  Â  Â  Â  Â  Â  if e_dt < s_dt: e_dt += timedelta(days=1)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  total_dur_sec = (e_dt - s_dt).total_seconds()
Â  Â  Â  Â  Â  Â  Â  Â  total_wagons = wag_map.get(f"{t}_Wagons", 0)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  curr = s_dt
Â  Â  Â  Â  Â  Â  Â  Â  while curr < e_dt:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  curr_day_str = curr.strftime('%Y-%m-%d')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  curr_date = curr.date()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  in_range = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if start_filter_dt and curr_date < start_filter_dt: in_range = False
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if end_filter_dt and curr_date > end_filter_dt: in_range = False
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  next_midnight = (curr + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  segment_end = min(e_dt, next_midnight)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  segment_dur_sec = (segment_end - curr).total_seconds()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  hours = segment_dur_sec / 3600.0
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if in_range:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if curr_day_str not in daily_stats:Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  daily_stats[curr_day_str] = {'Demurrage': 0, 'All_Reasons': set()}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for tx in ['T1', 'T2', 'T3', 'T4']:Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  daily_stats[curr_day_str][f'{tx}_hrs'] = 0.0
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  daily_stats[curr_day_str][f'{tx}_wag'] = 0.0
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  daily_stats[curr_day_str][f'{t}_hrs'] += hours
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if total_dur_sec > 0:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fraction = segment_dur_sec / total_dur_sec
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  daily_stats[curr_day_str][f'{t}_wag'] += (total_wagons * fraction)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  curr = segment_end

Â  Â  output_rows = []
Â  Â  for d, v in sorted(daily_stats.items()):
Â  Â  Â  Â  reasons_set = v['All_Reasons']
Â  Â  Â  Â  major_reasons_str = "\n".join(sorted(reasons_set)) if reasons_set else "-"

Â  Â  Â  Â  row = {
Â  Â  Â  Â  Â  Â  'Date': d,Â 
Â  Â  Â  Â  Â  Â  'Demurrage': f"{int(v['Demurrage'])} Hours",
Â  Â  Â  Â  Â  Â  'Major Reasons': major_reasons_str
Â  Â  Â  Â  }
Â  Â  Â  Â  for t in ['T1', 'T2', 'T3', 'T4']:
Â  Â  Â  Â  Â  Â  rate = 0.0
Â  Â  Â  Â  Â  Â  if v[f'{t}_hrs'] > 0.1: rate = v[f'{t}_wag'] / v[f'{t}_hrs']
Â  Â  Â  Â  Â  Â  row[f"{t} Rate (W/Hr)"] = f"{rate:.2f}"
Â  Â  Â  Â  output_rows.append(row)
Â  Â  Â  Â Â 
Â  Â  return pd.DataFrame(output_rows)

def highlight_bobr(row):
Â  Â  if 'BOBR' in str(row['Load Type']).upper():
Â  Â  Â  Â  return ['background-color: #FFD700; color: black'] * len(row)
Â  Â  return [''] * len(row)

# ==========================================
# 6. MAIN EXECUTION
# ==========================================

uploaded_file = st.file_uploader("Upload FOIS CSV File (Plan)", type=["csv"])

input_changed = False
if uploaded_file and ('last_file_id' not in st.session_state or st.session_state.last_file_id != uploaded_file.file_id):
Â  Â  input_changed = True
Â  Â  st.session_state.last_file_id = uploaded_file.file_id
if gs_url and ('last_gs_url' not in st.session_state or st.session_state.last_gs_url != gs_url):
Â  Â  input_changed = True
Â  Â  st.session_state.last_gs_url = gs_url

if input_changed or 'raw_data_cached' not in st.session_state:
Â  Â  actuals_df, unplanned_df, last_seq = pd.DataFrame(), pd.DataFrame(), (0,0)
Â  Â  if gs_url:
Â  Â  Â  Â  actuals_df, unplanned_df, last_seq = fetch_google_sheet_actuals(gs_url, sim_params['ft'])
Â  Â  st.session_state.actuals_df = actuals_df
Â  Â  st.session_state.unplanned_df = unplanned_df
Â  Â  st.session_state.last_seq = last_seq
Â  Â  if uploaded_file:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  uploaded_file.seek(0)
Â  Â  Â  Â  Â  Â  df_raw = pd.read_csv(uploaded_file)
Â  Â  Â  Â  Â  Â  df_raw.columns = df_raw.columns.str.strip().str.upper()
Â  Â  Â  Â  Â  Â  st.session_state.raw_data_cached = df_raw
Â  Â  Â  Â  except Exception: st.stop()
Â  Â  else: st.session_state.raw_data_cached = pd.DataFrame()

if 'raw_data_cached' in st.session_state or 'actuals_df' in st.session_state:
Â  Â  df_raw = st.session_state.get('raw_data_cached', pd.DataFrame())
Â  Â  df_act = st.session_state.get('actuals_df', pd.DataFrame())
Â  Â  df_unplanned = st.session_state.get('unplanned_df', pd.DataFrame())
Â  Â  start_seq = st.session_state.get('last_seq', (0,0))
Â  Â Â 
Â  Â  sim_result, sim_full_result, sim_start_dt = run_full_simulation_initial(
Â  Â  Â  Â  df_raw, sim_params, df_act, df_unplanned, start_seq
Â  Â  )
Â  Â  st.session_state.sim_result = sim_result
Â  Â  st.session_state.sim_full_result = sim_full_result
Â  Â  st.session_state.sim_start_dt = sim_start_dt

Â  Â  if 'sim_result' in st.session_state and not st.session_state.sim_result.empty:
Â  Â  Â  Â  df_final = st.session_state.sim_result
Â  Â  Â  Â  df_final['Date_Str'] = df_final['_Arrival_DT'].dt.strftime('%Y-%m-%d')
Â  Â  Â  Â  unique_dates = sorted(df_final['Date_Str'].unique())

Â  Â  Â  Â  tab_live, tab_hist = st.tabs(["ğŸš€ Live Schedule", "ğŸ“œ Historical Analysis"])

Â  Â  Â  Â  with tab_live:
Â  Â  Â  Â  Â  Â  col_cfg = {
Â  Â  Â  Â  Â  Â  Â  Â  "Rake": st.column_config.TextColumn("Rake Name", disabled=True),
Â  Â  Â  Â  Â  Â  Â  Â  "Coal Source": st.column_config.TextColumn("Source/Mine", disabled=True),
Â  Â  Â  Â  Â  Â  Â  Â  "Status": st.column_config.TextColumn("Status", help="ACTUAL = From G-Sheet"),
Â  Â  Â  Â  Â  Â  Â  Â  "Tippler Start Time": st.column_config.TextColumn("Start (dd-HH:MM)"),
Â  Â  Â  Â  Â  Â  Â  Â  "Finish Unload": st.column_config.TextColumn("Finish (dd-HH:MM)"),
Â  Â  Â  Â  Â  Â  Â  Â  "Extra Shunt (Mins)": st.column_config.NumberColumn("Ext. Shunt", step=5),
Â  Â  Â  Â  Â  Â  Â  Â  "_Arrival_DT": None, "_Shunt_Ready_DT": None, "_Form_Mins": None, "Date_Str": None, "_raw_wagon_counts": None, "_remarks": None
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  for d in unique_dates:
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"### ğŸ“… Schedule for {d}")
Â  Â  Â  Â  Â  Â  Â  Â  day_df = df_final[df_final['Date_Str'] == d].copy()
Â  Â  Â  Â  Â  Â  Â  Â  day_df.index = np.arange(1, len(day_df) + 1)
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(day_df.style.apply(highlight_bobr, axis=1), use_container_width=True, column_config=col_cfg)

Â  Â  Â  Â  Â  Â  yest_date = datetime.now(IST).date() - timedelta(days=1)
Â  Â  Â  Â  Â  Â  daily_stats_df = recalculate_cascade_reactive(st.session_state.sim_full_result, start_filter_dt=yest_date)
Â  Â  Â  Â  Â  Â  st.markdown("### ğŸ“Š Daily Performance & Demurrage Forecast")
Â  Â  Â  Â  Â  Â  st.dataframe(daily_stats_df, hide_index=True)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  st.download_button("ğŸ“¥ Download Final Report", df_final.drop(columns=["_Arrival_DT", "_Shunt_Ready_DT", "_Form_Mins", "Date_Str", "_raw_wagon_counts", "_remarks"]).to_csv(index=False).encode('utf-8'), "optimized_schedule.csv", "text/csv")

Â  Â  Â  Â  with tab_hist:
Â  Â  Â  Â  Â  Â  st.subheader("ğŸ” Past Performance Analysis")
Â  Â  Â  Â  Â  Â  col_h1, col_h2 = st.columns(2)
Â  Â  Â  Â  Â  Â  with col_h1:
Â  Â  Â  Â  Â  Â  Â  Â  view_mode = st.radio("Select View Mode", ["Day View", "Month View", "Custom Range"], horizontal=True)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  start_f, end_f = None, None
Â  Â  Â  Â  Â  Â  with col_h2:
Â  Â  Â  Â  Â  Â  Â  Â  if view_mode == "Day View":
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sel_date = st.date_input("Select Date", value=datetime.now(IST).date() - timedelta(days=1))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start_f, end_f = sel_date, sel_date
Â  Â  Â  Â  Â  Â  Â  Â  elif view_mode == "Month View":
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  c_m1, c_m2 = st.columns(2)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with c_m1: sel_month = st.selectbox("Month", range(1, 13), index=datetime.now().month - 1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with c_m2: sel_year = st.number_input("Year", value=datetime.now().year)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  import calendar
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  last_day = calendar.monthrange(sel_year, sel_month)[1]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start_f = datetime(sel_year, sel_month, 1).date()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  end_f = datetime(sel_year, sel_month, last_day).date()
Â  Â  Â  Â  Â  Â  Â  Â  else:Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  dr = st.date_input("Select Date Range", value=(datetime.now(IST).date()-timedelta(days=7), datetime.now(IST).date()))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(dr, tuple) and len(dr) == 2: start_f, end_f = dr
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if start_f and end_f:
Â  Â  Â  Â  Â  Â  Â  Â  hist_stats = recalculate_cascade_reactive(st.session_state.sim_full_result, start_filter_dt=start_f, end_filter_dt=end_f)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"**Performance Summary ({start_f} to {end_f})**")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(hist_stats, hide_index=True, use_container_width=True)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("---")
Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("Show Detailed Rake List (Demurrage Only)"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mask = (st.session_state.sim_full_result['_Arrival_DT'].dt.date >= start_f) & (st.session_state.sim_full_result['_Arrival_DT'].dt.date <= end_f)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  hist_raw = st.session_state.sim_full_result[mask].copy()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  def has_demurrage(val):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  s = str(val).strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return s != "00:00" and s != "0"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  hist_raw = hist_raw[hist_raw['Demurrage'].apply(has_demurrage)]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  hist_raw_clean = hist_raw.drop(columns=["_Arrival_DT", "_Shunt_Ready_DT", "_Form_Mins", "Date_Str", "_raw_wagon_counts", "_remarks"] + [f"{t}_{x}_Obj" for t in ['T1','T2','T3','T4'] for x in ['Start','End']], errors='ignore')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(hist_raw_clean, use_container_width=True)
